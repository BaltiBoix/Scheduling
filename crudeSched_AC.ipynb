{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyM8Vm0pc-GE"
      },
      "source": [
        "## 1. Entorno crudeSched"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAwj1foPc-GF"
      },
      "source": [
        "### 1.1. Establecer el entorno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjnIDGG5c-GG"
      },
      "source": [
        "En primer lugar cargaremos la librería __gym__ e inicializaremos el entorno."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not ('isColab' in locals()):\n",
        "    if 'google.colab' in str(get_ipython()):\n",
        "        print('Running on CoLab')\n",
        "        !pip install gymnasium\n",
        "        !wget https://github.com/BaltiBoix/Scheduling/raw/master/tankEnv.py\n",
        "        isColab = True\n",
        "    else:\n",
        "        print('Not running on CoLab')"
      ],
      "metadata": {
        "id": "JumIio7aSB_2",
        "outputId": "343b7868-bbdf-4974-abdd-4b100a1126f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.8/dist-packages (0.27.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium) (4.5.0)\n",
            "Requirement already satisfied: jax-jumpy>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium) (0.2.0)\n",
            "Requirement already satisfied: gymnasium-notices>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from gymnasium) (0.0.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gymnasium) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gymnasium) (3.13.0)\n",
            "--2023-02-20 16:23:52--  https://github.com/BaltiBoix/Scheduling/raw/master/tankEnv.py\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BaltiBoix/Scheduling/master/tankEnv.py [following]\n",
            "--2023-02-20 16:23:52--  https://raw.githubusercontent.com/BaltiBoix/Scheduling/master/tankEnv.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22012 (21K) [text/plain]\n",
            "Saving to: ‘tankEnv.py.1’\n",
            "\n",
            "tankEnv.py.1        100%[===================>]  21.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-20 16:23:52 (131 MB/s) - ‘tankEnv.py.1’ saved [22012/22012]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "44GG2cz6c-GH",
        "outputId": "8eeb0f59-2d2c-413c-bb51-cffe7aa326da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gymnasium/envs/registration.py:435: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gymnasium/utils/passive_env_checker.py:35: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (2, 10)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gymnasium/utils/passive_env_checker.py:35: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (2, 5)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gymnasium/utils/passive_env_checker.py:35: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (7, 10)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gymnasium/utils/passive_env_checker.py:35: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (7, 5)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import flatten as flat\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy, copy\n",
        "from collections import namedtuple, deque, OrderedDict\n",
        "import os\n",
        "import IPython.display\n",
        "import sklearn\n",
        "import sklearn.pipeline\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "\n",
        "import tankEnv\n",
        "\n",
        "env = gym.envs.make('crudeTanksEnv-v0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkjAHGpcc-GI",
        "outputId": "4fd288ae-b9e2-415e-d6df-832aebbbebc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is torch cuda available?: True\n"
          ]
        }
      ],
      "source": [
        "print('Is torch cuda available?: {}'.format(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdorKPAmQ0-4",
        "outputId": "35259e5f-87c4-432a-e1ae-5833e00645c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnvSpec(id='crudeTanksEnv-v0', entry_point=<class 'tankEnv.crudeTanksEnv'>, reward_threshold=500, nondeterministic=False, max_episode_steps=720, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='crudeTanksEnv', version=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "env.spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xWJ4zbmNQ0-4"
      },
      "outputs": [],
      "source": [
        "class dStat():\n",
        "    def __init__(self, env, seed=None, scale=True):\n",
        "        self.dState = deque(maxlen=2)\n",
        "        self.env = env\n",
        "        self.seed = seed\n",
        "        self.scale = scale\n",
        "        if self.scale:\n",
        "            self.fitScaler()\n",
        "        else:\n",
        "            self.scaler = None\n",
        "        return\n",
        "    \n",
        "    def reset(self):\n",
        "        self.dState.clear()\n",
        "        state, data = self.env.reset(seed=self.seed)\n",
        "        self.dState.append(self.transform(state))\n",
        "        for _ in range(10):\n",
        "            action = self.env.action_space.sample()\n",
        "            if data['actionAvail'][0][action['farmTanks'][0]] and data['actionAvail'][1][action['farmTanks'][1]]:\n",
        "              break\n",
        "        self.dState[0] = np.append(self.dState[0], flat(self.env.action_space, action))\n",
        "        state, reward, done, _, info = self.env.step(action)\n",
        "        data['actionAvail'] = info['actionAvail']\n",
        "        self.dState.append(self.transform(state))\n",
        "        return np.append(*self.dState), data\n",
        "        \n",
        "    def step(self, action):\n",
        "        state, reward, done, truncated, info = self.env.step(action)\n",
        "        self.dState.append(self.transform(state))\n",
        "        self.dState[0] = np.append(self.dState[0], flat(self.env.action_space, action))\n",
        "        return np.append(*self.dState), reward, done, truncated, info\n",
        "    \n",
        "    def fitScaler(self):\n",
        "        observation_examples = np.array([flat(self.env.observation_space, self.env.observation_space.sample())\\\n",
        "                                         for x in range(10000)])\n",
        "        self.scaler = sklearn.preprocessing.StandardScaler()\n",
        "        self.scaler.fit(observation_examples)\n",
        "        return\n",
        "    \n",
        "    def transform(self, state):\n",
        "        if self.scaler is None:\n",
        "            return flat(self.env.observation_space, state)\n",
        "        return self.scaler.transform([flat(self.env.observation_space, state)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_SfRbufVQ0-5"
      },
      "outputs": [],
      "source": [
        "dSt = dStat(env, scale=False)\n",
        "state, data = dSt.reset()\n",
        "stateShape = state.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UA4SPt96-tH"
      },
      "source": [
        "## Actor-Critic method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmpmuawyAr66"
      },
      "source": [
        "Basado en el ejemplo de pytorch:  \n",
        "\n",
        "https://github.com/pytorch/examples/blob/main/reinforcement_learning/actor_critic.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1tbKMQI-6-tU"
      },
      "outputs": [],
      "source": [
        "class AC_actor(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, env, n_inputs, learning_rate=1e-3, device='cpu'):\n",
        "        \"\"\"\n",
        "        Actor ANN\n",
        "        \"\"\"\n",
        "        super(AC_actor, self).__init__()\n",
        "\n",
        "        self.n_inputs = n_inputs\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        if torch.cuda.is_available() and device=='cuda':\n",
        "            self.device = 'cuda'\n",
        "        else:\n",
        "            self.device = 'cpu'\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # AC Actor\n",
        "        self.actor = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.n_inputs, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 256, bias=True),\n",
        "            torch.nn.ReLU()       \n",
        "        )\n",
        "        self.actorC = torch.nn.Sequential(\n",
        "            torch.nn.Linear(256, 256, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128, bias=True),\n",
        "            torch.nn.ReLU(),       \n",
        "            torch.nn.Linear(128, 1, bias=True),\n",
        "            torch.nn.Softplus()\n",
        "        )\n",
        "        self.actorD1 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(256, 256, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128, bias=True),\n",
        "            torch.nn.ReLU(),       \n",
        "            torch.nn.Linear(128, 13, bias=True),\n",
        "            torch.nn.Softmax(dim=-1)\n",
        "        )\n",
        "        self.actorD2 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(256, 256, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128, bias=True),\n",
        "            torch.nn.ReLU(),       \n",
        "            torch.nn.Linear(128, 6, bias=True),\n",
        "            torch.nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "        if self.device == 'cuda':\n",
        "            self.actor.cuda()\n",
        "            self.actorC.cuda()\n",
        "            self.actorD1.cuda()\n",
        "            self.actorD2.cuda()\n",
        "        \n",
        "        self.register_parameter(name='lognu', param=torch.nn.Parameter(torch.tensor(0.1).to(device=self.device)))\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        # self.lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', \n",
        "        #                                                            patience=200, factor=0.5, min_lr=0.0001, verbose=True)\n",
        "\n",
        "        # self.init_weights()\n",
        "\n",
        "    #Obtención de las probabilidades de las posibles acciones\n",
        "    def get_action(self, state):\n",
        "        state_t = torch.FloatTensor(state).to(device=self.device)\n",
        "        tmp = self.actor(state_t)\n",
        "        \n",
        "        mu = self.actorC(tmp)\n",
        "        if torch.isnan(mu):\n",
        "            mu = torch.tensor(1.0, device=self.device)\n",
        "            print('nan mu')\n",
        "        nu = torch.clamp(self.lognu.exp(), 1e-3, 2)\n",
        "        \n",
        "        return torch.distributions.Normal(mu, nu),\\\n",
        "               torch.distributions.Categorical(self.actorD1(tmp)),\\\n",
        "               torch.distributions.Categorical(self.actorD2(tmp))\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.actor.apply(self.init_weights_)\n",
        "\n",
        "    def init_weights_(self, m):\n",
        "        if isinstance(m, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            m.bias.data.fill_(pow(5., -0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pcVFk2oB-Idp"
      },
      "outputs": [],
      "source": [
        "class AC_critic(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, env, n_inputs, learning_rate=1e-3, device='cpu'):\n",
        "        \"\"\"\n",
        "        Critic ANN\n",
        "        \"\"\"\n",
        "        super(AC_critic, self).__init__()\n",
        "\n",
        "        self.n_inputs = n_inputs\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        if torch.cuda.is_available() and device=='cuda':\n",
        "            self.device = 'cuda'\n",
        "        else:\n",
        "            self.device = 'cpu'\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # AC Critic\n",
        "        self.critic = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.n_inputs, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 256, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 1, bias=True)\n",
        "        )\n",
        "\n",
        "        if self.device == 'cuda':\n",
        "            self.critic.cuda()\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        # self.lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', \n",
        "        #                                                            patience=200, factor=0.5, min_lr=0.00001)\n",
        "    \n",
        "    def get_val(self, state):\n",
        "        state_t = torch.FloatTensor(state).to(device=self.device)\n",
        "        return self.critic(state_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1psxD6vR6-tV"
      },
      "source": [
        "\n",
        "### Definición del agente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e1iFeZ8T6-tV"
      },
      "outputs": [],
      "source": [
        "class ACAgent:\n",
        "\n",
        "    def __init__(self, env, dnnet_actor, dnnet_critic, nblock=100):\n",
        "        \"\"\"\n",
        "        Params\n",
        "        ======\n",
        "        env: entorno\n",
        "        dnnetwork: clase con la red neuronal diseñada\n",
        "        nblock: bloque de los X últimos episodios de los que se calculará la media de recompensa\n",
        "        reward_threshold: umbral de recompensa definido en el entorno\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.dnnet_actor = dnnet_actor\n",
        "        self.dnnet_critic = dnnet_critic\n",
        "        self.device = dnnet_actor.device\n",
        "        self.nblock = nblock\n",
        "        self.reward_threshold = env.spec.reward_threshold\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        self.losses = []\n",
        "        self.update_loss = []\n",
        "        self.training_rewards = []\n",
        "        self.mean_training_rewards = []\n",
        "    ######\n",
        "\n",
        "    ## Entrenamiento\n",
        "    def train(self, gamma=0.99, max_episodes=2000):\n",
        "        self.gamma = gamma\n",
        "\n",
        "        episode = 0\n",
        "        self.mean_rewards = -1000.0\n",
        "        self.maxRewards = 0.0\n",
        "        training = True\n",
        "        print(\"Training...\")\n",
        "        epsilon = 0.0\n",
        "        epsilon_min = 0.0\n",
        "        dSt = dStat(env, seed=200560)\n",
        "        while training:\n",
        "            state0, data = dSt.reset()\n",
        "            actionAvail = data['actionAvail']\n",
        "            episode_rewards = []\n",
        "            episode_vals = []\n",
        "            episode_prob_logs = []\n",
        "            gamedone = False\n",
        "            t = 1\n",
        "            while gamedone == False:\n",
        "                cProb, d1Prob, d2Prob = self.dnnet_actor.get_action(state0)\n",
        "                cAction = cProb.sample()\n",
        "                cAction = torch.clamp(cAction, 0.1, 1.0)\n",
        "                #d1Prob = torch.distributions.Categorical(d1Prob.probs * torch.tensor(actionAvail[0], device=self.dnnet_actor.device))\n",
        "                #d2Prob = torch.distributions.Categorical(d2Prob.probs * torch.tensor(actionAvail[1], device=self.dnnet_actor.device))\n",
        "                if actionAvail[0].any():\n",
        "                    d1Prob.probs = d1Prob.probs * torch.tensor(actionAvail[0]+1E-5, device=self.dnnet_actor.device)\n",
        "                if actionAvail[1].any():\n",
        "                    d2Prob.probs = d2Prob.probs * torch.tensor(actionAvail[1]+1E-5, device=self.dnnet_actor.device)\n",
        "                d1Action = d1Prob.sample()\n",
        "                d2Action = d2Prob.sample()\n",
        "                if np.random.random() < epsilon:\n",
        "                    for _ in range(10): \n",
        "                        action = env.action_space.sample() # acción aleatoria\n",
        "                        if actionAvail[0][action['farmTanks'][0]] and actionAvail[1][action['farmTanks'][1]]:\n",
        "                          break\n",
        "                    d1Action = torch.tensor(action['farmTanks'][0], device=self.dnnet_actor.device, dtype=torch.int)\n",
        "                    d2Action = torch.tensor(action['farmTanks'][1], device=self.dnnet_actor.device, dtype=torch.int)\n",
        "                    action['unitFeed'] = np.array([cAction.item()])\n",
        "                    #cAction = torch.tensor(action['unitFeed'], device=self.dnnet_actor.device, dtype=torch.int)\n",
        "                else:\n",
        "                    action = OrderedDict({'farmTanks': np.array([d1Action.item(), d2Action.item()]),\n",
        "                                          'unitFeed': np.array([cAction.item()])})\n",
        "                \n",
        "                val = self.dnnet_critic.get_val(state0)\n",
        "                episode_vals.append(val)\n",
        "                \n",
        "                prob_log = cProb.log_prob(cAction) + d1Prob.log_prob(d1Action) + d2Prob.log_prob(d2Action)\n",
        "                episode_prob_logs.append(prob_log)\n",
        "\n",
        "                new_state, reward, gamedone, _, info = dSt.step(action)\n",
        "                actionAvail = info['actionAvail']\n",
        "                \n",
        "                # Almacenamos experiencias que se van obteniendo en este episodio\n",
        "                episode_rewards.append(reward)\n",
        "\n",
        "                state0 = deepcopy(new_state)\n",
        "                t += 1\n",
        "\n",
        "            episode += 1\n",
        "            n_steps = len(episode_rewards)\n",
        "            \n",
        "            episode_discounted_rewards = torch.tensor(self.discount_rewards(episode_rewards), device=self.dnnet_critic.device, dtype=torch.float)\n",
        "\n",
        "            self.dnnet_actor.optimizer.zero_grad()\n",
        "            self.dnnet_critic.optimizer.zero_grad()\n",
        "\n",
        "            advantage = episode_discounted_rewards - torch.cat(episode_vals)\n",
        "\n",
        "            loss_actor = -(torch.stack(episode_prob_logs) * advantage.detach()).mean()\n",
        "\n",
        "            loss_critic = advantage.square().mean()\n",
        "\n",
        "            loss_actor.backward() # hacemos la diferencia para obtener los gradientes\n",
        "            loss_critic.backward() # hacemos la diferencia para obtener los gradientes\n",
        "\n",
        "            self.dnnet_actor.optimizer.step() # aplicamos los gradientes a la red neuronal\n",
        "#             self.dnnet_actor.lr_sched.step(self.mean_rewards)\n",
        "\n",
        "            self.dnnet_critic.optimizer.step() # aplicamos los gradientes a la red neuronal\n",
        "#             self.dnnet_critic.lr_sched.step(self.mean_rewards)\n",
        "\n",
        "            self.training_rewards.append(sum(episode_rewards)) # guardamos las recompensas obtenidas\n",
        "            self.mean_rewards = np.mean(self.training_rewards[-self.nblock:])\n",
        "            self.mean_training_rewards.append(self.mean_rewards)\n",
        "\n",
        "            if self.training_rewards[-1] > self.maxRewards:\n",
        "                self.maxRewards = self.training_rewards[-1]\n",
        "                self.maxS = deepcopy(env.S)\n",
        "\n",
        "            # Comprobamos que todavía quedan episodios\n",
        "            if episode >= max_episodes:\n",
        "                training = False\n",
        "                print('\\nEpisode limit reached.')\n",
        "                break\n",
        "\n",
        "            if episode > 100 and episode % 100 == 0:\n",
        "                self.plot_rewards()\n",
        "\n",
        "            print(\"\\rEpisode {:3d} Mean Rewards {:.2f} Last Reward {:.2f} n steps {:3d}  epsilon {:.3f}\\t\\t\".format(\n",
        "                episode, self.mean_rewards, np.mean(self.training_rewards[-1]), n_steps+1, epsilon), end=\"\")\n",
        "\n",
        "            epsilon = max(epsilon*0.995, epsilon_min)\n",
        "            \n",
        "            # Termina el juego si la media de recompensas ha llegado al umbral fijado para este juego\n",
        "            if self.mean_rewards >= self.reward_threshold and episode > 4*self.nblock:\n",
        "                training = False\n",
        "                print('\\nEnvironment solved in {} episodes!'.format(\n",
        "                    episode))\n",
        "                break\n",
        "\n",
        "    def discount_rewards(self, rewards):\n",
        "        discount_r = np.zeros_like(rewards)\n",
        "        timesteps = range(len(rewards))\n",
        "        reward_sum = 0\n",
        "        for i in reversed(timesteps):\n",
        "            reward_sum = rewards[i] + self.gamma*reward_sum\n",
        "            discount_r[i] = reward_sum\n",
        "        #(discount_r - np.mean(discount_r))/max(np.std(discount_r), np.finfo(np.float32).eps)\n",
        "        return (discount_r - np.mean(discount_r))/max(np.std(discount_r), np.finfo(np.float32).eps)\n",
        "        # return discount_r - np.mean(discount_r)\n",
        "\n",
        "    def plot_rewards(self):\n",
        "       \n",
        "        IPython.display.clear_output(wait=True)\n",
        "\n",
        "        plt.figure(figsize=(12,8))\n",
        "        plt.plot(self.training_rewards, label='Rewards')\n",
        "        plt.plot(self.mean_training_rewards, label='Mean Rewards')\n",
        "        plt.axhline(self.env.spec.reward_threshold, color='r', label=\"Reward threshold\")\n",
        "        plt.xlabel('Episodes')\n",
        "        plt.ylabel('Rewards')\n",
        "        plt.legend(loc=\"upper left\")\n",
        "        plt.grid()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYRA7DMb6-tX"
      },
      "source": [
        "### Entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iL8iV_kM6-tX"
      },
      "outputs": [],
      "source": [
        "lr_actor = 1.E-5     #Velocidad de aprendizaje \n",
        "lr_critic = 5.E-4    #Velocidad de aprendizaje \n",
        "GAMMA = 0.99         #Valor gamma de la ecuación de Bellman\n",
        "NBLOCK = 100         #Número de steps para rellenar el buffer\n",
        "MAX_EPISODES = 5000  #Número máximo de episodios (el agente debe aprender antes de llegar a este valor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UTAxECge6-tX"
      },
      "outputs": [],
      "source": [
        "ACa = AC_actor(env, stateShape, learning_rate=lr_actor, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ctVGWP0tAxGK"
      },
      "outputs": [],
      "source": [
        "ACc = AC_critic(env, stateShape, learning_rate=lr_critic, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4OEDtMh06-tX"
      },
      "outputs": [],
      "source": [
        "AC_agent = ACAgent(env, ACa, ACc, NBLOCK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "uEZfeX5A6-tY",
        "outputId": "352cc019-2745-4d41-b9b9-cdb990c0582a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1067 Mean Rewards -86.79 Last Reward -87.30 n steps 720  epsilon 0.000\t\t"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-da5ed35de944>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gamma, max_episodes)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mgamedone\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mcProb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1Prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2Prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnnet_actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mcAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mcAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcAction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-fbecfa22e27b>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactorD1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactorD2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/constraints.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "AC_agent.train(gamma=GAMMA, max_episodes=MAX_EPISODES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "j1RbpVEFQ0-9",
        "outputId": "198ae15e-8df5-4594-daff-d0dc82894cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d7ae59b61bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAC_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'ACAgent' object has no attribute 'maxS'"
          ]
        }
      ],
      "source": [
        "AC_agent.maxS.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI0G9ycNQ0-9"
      },
      "outputs": [],
      "source": [
        "AC_agent.maxS.prodsLog[300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJNdFGOUQ0-9"
      },
      "outputs": [],
      "source": [
        "AC_agent.plot_rewards()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK4g1sv1Q0-9"
      },
      "outputs": [],
      "source": [
        "myfile = 'agentACDT_Trained_Model.pth'\n",
        "if os.path.isfile(myfile):\n",
        "    os.remove(myfile)\n",
        "torch.save(ACa.state_dict(), myfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-L7Px1ZQ0--"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "env = gym.envs.make(\"crudeTanksEnv-v0\")\n",
        "\n",
        "AC = AC_actor(env, 512, learning_rate=0.005, device='cuda')\n",
        "AC.load_state_dict(torch.load(myfile))\n",
        "\n",
        "state0 = flat(env.observation_space, env.reset()[0])\n",
        "done = False\n",
        "episode_reward = 0\n",
        "n = 0\n",
        "action_list = []\n",
        "while not done:\n",
        "    cProb, d1Prob, d2Prob = AC.get_action(state0)\n",
        "    cAction = cProb.sample()\n",
        "    cAction = torch.clamp(cAction, min=0.1, max=1.0)\n",
        "    d1Action = d1Prob.sample()\n",
        "    d2Action = d2Prob.sample()\n",
        "    action = OrderedDict({'farmTanks': np.array([d1Action.item(), d2Action.item()]),\n",
        "                          'unitFeed': np.array([cAction.item()])})\n",
        "    state, reward, done, _, _ = env.step(action)\n",
        "    state = flat(env.observation_space, state)\n",
        "    episode_reward += reward\n",
        "    n += 1\n",
        "    state0 = deepcopy(state)\n",
        "    if n >= env.spec.max_episode_steps:\n",
        "        done = True\n",
        "\n",
        "print('n: {:4d}   reward: {:4.2f}'.format(n, episode_reward))\n",
        "env.render()\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlfidoUSQ0--"
      },
      "outputs": [],
      "source": [
        "list(AC.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jY2slc2Q0--"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "env = gym.envs.make(\"crudeTanksEnv-v0\")\n",
        "\n",
        "AC = AC_actor(env, 512, learning_rate=0.005, device='cuda')\n",
        "AC.load_state_dict(torch.load(myfile))\n",
        "\n",
        "reward_list = []\n",
        "n_list = []\n",
        "for n_episodes in range(20):\n",
        "    state0 = flat(env.observation_space, env.reset()[0])\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    n = 0\n",
        "    action_list = []\n",
        "    while not done:\n",
        "        cProb, d1Prob, d2Prob = AC.get_action(state0)\n",
        "        cAction = cProb.sample()\n",
        "        d1Action = d1Prob.sample()\n",
        "        d2Action = d2Prob.sample()\n",
        "        action = OrderedDict({'farmTanks': np.array([d1Action.item(), d2Action.item()]),\n",
        "                              'unitFeed': np.array([cAction.item()])})\n",
        "        state, reward, done, _, _ = env.step(action)\n",
        "        state = flat(env.observation_space, state)\n",
        "        episode_reward += reward\n",
        "        n += 1\n",
        "        state0 = deepcopy(state)\n",
        "        if n >= env.spec.max_episode_steps:\n",
        "            done = True\n",
        "\n",
        "    print('{:2d} n: {:4d}   reward: {:4.2f}'.format(n_episodes+1, n, episode_reward))\n",
        "    reward_list.append(episode_reward)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF3V5G9_Q0--"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "\n",
        "fig.suptitle('Recompensa de 20 partidas con el modelo ajustado')\n",
        "\n",
        "ax.plot(reward_list)\n",
        "ax.axhline(y=env.spec.reward_threshold, color='r', linestyle='-')\n",
        "ax.set_xlabel('suma de recompensas de cada partida')\n",
        "ax.set_xticks(range(20))\n",
        "ax.grid()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "rl",
      "language": "python",
      "name": "rl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}